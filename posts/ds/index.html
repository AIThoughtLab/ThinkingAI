<!doctype html><html lang=en><head><title>Understanding the Dempster-Shafer Theory for Deep Learning · AI for HUMANITY</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Mohamed ABDUL GAFOOR"><meta name=description content="Introduction
The Dempster-Shafer theory (DST), named after its creators Arthur Dempster and Glenn Shafer, is a powerful mathematical framework for representing and managing uncertain information. It is particularly useful in situations where the available data is incomplete, imprecise, or contradictory. In this post, we will introduce the core concepts of the Dempster-Shafer theory, explore its practical applications in deep learning, and discuss its advantages over traditional probability theory.
Belief functions"><meta name=keywords content="blog,developer,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="Understanding the Dempster-Shafer Theory for Deep Learning"><meta name=twitter:description content="Introduction
The Dempster-Shafer theory (DST), named after its creators Arthur Dempster and Glenn Shafer, is a powerful mathematical framework for representing and managing uncertain information. It is particularly useful in situations where the available data is incomplete, imprecise, or contradictory. In this post, we will introduce the core concepts of the Dempster-Shafer theory, explore its practical applications in deep learning, and discuss its advantages over traditional probability theory.
Belief functions"><meta property="og:title" content="Understanding the Dempster-Shafer Theory for Deep Learning"><meta property="og:description" content="Introduction
The Dempster-Shafer theory (DST), named after its creators Arthur Dempster and Glenn Shafer, is a powerful mathematical framework for representing and managing uncertain information. It is particularly useful in situations where the available data is incomplete, imprecise, or contradictory. In this post, we will introduce the core concepts of the Dempster-Shafer theory, explore its practical applications in deep learning, and discuss its advantages over traditional probability theory.
Belief functions"><meta property="og:type" content="article"><meta property="og:url" content="https://AIThoughtLab.github.io/ThinkingAI/posts/ds/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-09-30T00:00:00+00:00"><meta property="article:modified_time" content="2022-09-30T00:00:00+00:00"><link rel=canonical href=https://AIThoughtLab.github.io/ThinkingAI/posts/ds/><link rel=preload href="https://AIThoughtLab.github.io/ThinkingAI/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin><link rel=stylesheet href=https://AIThoughtLab.github.io/ThinkingAI/css/coder.min.36f76aaf39a14ecf5c3a3c6250dcaf06c238b3d8365d17d646f95cb1874e852b.css integrity="sha256-NvdqrzmhTs9cOjxiUNyvBsI4s9g2XRfWRvlcsYdOhSs=" crossorigin=anonymous media=screen><link rel=stylesheet href=https://AIThoughtLab.github.io/ThinkingAI/css/coder-dark.min.593028e7f7ac55c003b79c230d1cd411bb4ca53b31556c3abb7f027170e646e9.css integrity="sha256-WTAo5/esVcADt5wjDRzUEbtMpTsxVWw6u38CcXDmRuk=" crossorigin=anonymous media=screen><link rel=icon type=image/png href=https://AIThoughtLab.github.io/ThinkingAI/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=https://AIThoughtLab.github.io/ThinkingAI/images/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=https://AIThoughtLab.github.io/ThinkingAI/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=https://AIThoughtLab.github.io/ThinkingAI/images/apple-touch-icon.png><link rel=manifest href=https://AIThoughtLab.github.io/ThinkingAI/site.webmanifest><link rel=mask-icon href=https://AIThoughtLab.github.io/ThinkingAI/images/safari-pinned-tab.svg color=#5bbad5><meta name=generator content="Hugo 0.111.3"></head><body class="preload-transitions colorscheme-dark"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://AIThoughtLab.github.io/ThinkingAI/>AI for HUMANITY</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/about/>About</a></li><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/posts/>Blog</a></li><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/projects/>Projects</a></li><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/physics/>PINN</a></li><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/innovations/>Innovations</a></li><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/personal/>Personal</a></li><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/contact/>Contact me</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://AIThoughtLab.github.io/ThinkingAI/posts/ds/>Understanding the Dempster-Shafer Theory for Deep Learning</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa fa-calendar" aria-hidden=true></i>
<time datetime=2022-09-30T00:00:00Z>September 30, 2022</time></span>
<span class=reading-time><i class="fa fa-clock-o" aria-hidden=true></i>
6-minute read</span></div><div class=categories><i class="fa fa-folder" aria-hidden=true></i>
<a href=https://AIThoughtLab.github.io/ThinkingAI/categories/artificial-intelligence/>Artificial Intelligence</a></div><div class=tags><i class="fa fa-tag" aria-hidden=true></i>
<span class=tag><a href=https://AIThoughtLab.github.io/ThinkingAI/tags/dempster-shafer/>Dempster-Shafer</a></span>
<span class=separator>•</span>
<span class=tag><a href=https://AIThoughtLab.github.io/ThinkingAI/tags/machine-learning/>Machine Learning</a></span>
<span class=separator>•</span>
<span class=tag><a href=https://AIThoughtLab.github.io/ThinkingAI/tags/deep-learning/>Deep Learning</a></span></div></div></header><div class=post-content><p><strong>Introduction</strong></p><p>The Dempster-Shafer theory (DST), named after its creators Arthur Dempster and Glenn Shafer, is a powerful mathematical framework for representing and managing uncertain information. It is particularly useful in situations where the available data is incomplete, imprecise, or contradictory. In this post, we will introduce the core concepts of the Dempster-Shafer theory, explore its practical applications in deep learning, and discuss its advantages over traditional probability theory.</p><p><strong>Belief functions</strong></p><p>In the DST, uncertain information is represented by belief functions. A belief function, also known as a basic probability assignment (BPA), is a mapping from subsets of the set of possible outcomes, called the frame of discernment, to the interval [0, 1]. The sum of all BPAs over the power set of the frame of discernment (excluding the empty set) is equal to 1.</p><p><strong>Belief, plausibility, and interval-valued probability</strong></p><p>The belief function allows us to define two important measures: belief and plausibility. The belief of an event is the sum of the BPAs assigned to all subsets that contain the event. The plausibility of an event is the sum of the BPAs assigned to all subsets that intersect with the event. The interval between the belief and plausibility of an event is referred to as the interval-valued probability. In the following figure interval-valued probability is a representation of uncertainty.</p><figure class=center><img src=https://AIThoughtLab.github.io/ThinkingAI/images/ds1.png></figure><p><strong>Dempster&rsquo;s rule of combination</strong></p><p>Dempster&rsquo;s rule of combination, which is a crucial aspect of the Dempster-Shafer theory, is a rule for combining two or more belief functions related to the same frame of discernment. The combined belief function is computed by normalizing the sum of the product of BPAs assigned to compatible subsets.</p><p>Given two belief functions \(m1\) and \(m2\), the combined belief function \(m\) is calculated for each subset A of the frame of discernment \(\Theta\) using the equation:</p><p>$$m(A) = \frac{\sum_{X \cap Y = A} m_{1}(X) \cdot m_{2}(Y)}{1 - K}$$</p><p>where the summation is over all pairs of subsets \(X\) and \(Y\) such that \(X ∩ Y = A\), and \(K\) is a normalization factor calculated as:</p><p>$$K = \sum_{X \cap Y = \emptyset} m_{1}(X) \cdot m_{2}(Y)$$</p><p>where the summation is over all pairs of subsets \(X\) and \(Y\) such that \(X ∩ Y = ∅\) (empty set).</p><p>COMPLICATED???</p><figure class=center><img src=https://AIThoughtLab.github.io/ThinkingAI/images/com.png></figure><p>Let us see an example!! Suppose we want to diagnose a patient based on the symptoms they are experiencing. We have three possible diseases: Disease A \((D_A)\), Disease B \((D_B)\), and Disease C \((D_C)\). We have two different tests (Test 1 and Test 2) that provide evidence about the presence of these diseases.</p><p>Frame of discernment \(\Theta\): We have two possible outcomes - Intruder Present \(I\) and Intruder Absent \(A\).
Frame of discernment \(\Theta\): \({D_A, D_B, D_C}\)</p><p><strong>Evidence from Test 1:</strong></p><p>Suppose Test 1 provides the following belief functions:</p><ul><li>Belief in Disease A \((D_A)\): 0.5</li><li>Belief in Disease B \((D_B)\): 0.1</li><li>Belief in Disease C \((D_C)\): 0.1</li><li>Belief in Don&rsquo;t Know \((D_A ∪ D_B ∪ D_C)\): 0.3</li></ul><p><strong>Evidence from Test 2:</strong></p><p>Suppose Test 2 provides the following belief functions:</p><ul><li>Belief in Disease A \((D_A)\): 0.3</li><li>Belief in Disease B \((D_B)\): 0.4</li><li>Belief in Disease C \((D_C)\): 0.1</li><li>Belief in Don&rsquo;t Know \((D_A ∪ D_B ∪ D_C)\): 0.2</li></ul><p>We can combine the belief functions from both tests using Dempster&rsquo;s rule. The combined belief function is computed by normalizing the sum of the product of BPAs assigned to compatible subsets.</p><p>To compute the combined belief for each hypothesis, we first calculate the joint mass;
\(m(D_A) = m1(D_A) * m2(D_A) = 0.5 * 0.3 = 0.15\)
\(m(D_B) = m1(D_B) * m2(D_B) = 0.1 * 0.4 = 0.04\)
\(m(D_C) = m1(D_C) * m2(D_C) = 0.1 * 0.1 = 0.01\)</p><p>Sum of all compatible subset product combinations;</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-Python data-lang=Python><span style=display:flex><span>m(D_A <span>∪</span> D_B <span>∪</span> D_C) = m1(D_A) * m2(D_A <span>∪</span> D_B <span>∪</span> D_C) + m1(D_B) * m2(D_A <span>∪</span> D_B <span>∪</span> D_C) + m1(D_C) * m2(D_A <span>∪</span> D_B <span>∪</span> D_C) + m1(D_A <span>∪</span> D_B <span>∪</span> D_C) * m2(D_A) + m1(D_A <span>∪</span> D_B <span>∪</span> D_C) * m2(D_B) + m1(D_A <span>∪</span> D_B <span>∪</span> D_C) * m2(D_C)
</span></span></code></pre></div><p>Hence,</p><p>\(m(D_A ∪ D_B ∪ D_C) = 0.5 * 0.2 + 0.1 * 0.3 + 0.1 * 0.4 + 0.1 * 0.2 + 0.1 * 0.1 + 0.3 * 0.3 = 0.1 + 0.03 + 0.04 + 0.02 + 0.01 + 0.09 = 0.29\)</p><p>Now, we normalize the joint mass;</p><p>\(K = 1 / (1 - m(D_A ∪ D_B ∪ D_C)) = 1 / (1 - 0.29) = 1 / 0.71 ≈ 1.408\)</p><p>Finally, we calculate the normalized belief functions;</p><p>\(Bel(D_A) = m(D_A) * K = 0.15 * 1.408 ≈ 0.211\)
\(Bel(D_B) = m(D_B) * K = 0.04 * 1.408 ≈ 0.056\)
\(Bel(D_C) = m(D_C) * K = 0.01 * 1.408 ≈ 0.014\)</p><p>After combining the evidence from both tests, we have the following belief functions;</p><p>\(Bel(D_A) ≈ 0.211\),
\(Bel(D_B) ≈ 0.056\),
\(Bel(D_C) ≈ 0.014\)</p><p>Therefore, based on the combined belief values, Disease A appears to be the most likely diagnosis, followed by Disease B and Disease C. However, it is important to note that these belief values do not provide definitive answers but rather indicate the strength of the evidence for each disease hypothesis. Further tests or expert consultation may be necessary to make a more accurate diagnosis.</p><p><strong>Dempster-Shafer theory in deep learning</strong></p><p>Integrating the Dempster-Shafer theory into deep learning can help improve the robustness and interpretability of the models, especially in situations where the data is incomplete or ambiguous. Here are some steps to incorporate the Dempster-Shafer theory into our deep learning models;</p><ul><li><p>First of all, identify the problem that we want to solve using deep learning and define the frame of discernment \(\Theta\), which represents the set of all possible outcomes or classes.</p></li><li><p>Design: Design a deep learning model, such as a convolutional neural network (CNN) to process the input data and generate the initial outputs or predictions. We can use standard deep learning frameworks like TensorFlow for this purpose.</p></li><li><p>Generate belief functions: Instead of generating a single probability value for each class, modify the output layer of the deep learning model to generate belief functions (basic probability assignments or BPAs). These BPAs can be calculated based on the outputs from the softmax activation function, by transforming or mapping them according to the problem requirements and the level of uncertainty in our data.</p></li><li><p>Combine belief functions: If we have multiple sources of evidence (e.g. motion sensor and a sound sensor) for the same problem, use Dempster&rsquo;s rule of combination to combine the belief functions obtained from these sources. This will result in a new belief function that provides a more comprehensive representation of the uncertainty in our data.</p></li><li><p>Calculate belief and plausibility: Compute the belief and plausibility values for each class using the combined belief functions. These values provide an interval-valued probability, which can help us better understand the uncertainty associated with each class prediction.</p></li><li><p>Model interpretation and decision-making: Use the belief and plausibility values to interpret the results of our deep learning model, and make more informed decisions based on these values. For example, we can choose the class with the highest plausibility value as the most plausible prediction or use the interval-valued probability to quantify the level of uncertainty in our model&rsquo;s predictions.</p></li><li><p>Evaluate and fine-tune: Evaluate the performance of the Dempster-Shafer enhanced deep learning model using relevant metrics (e.g., accuracy, F1-score). Based on the evaluation results, fine-tune the model by adjusting its architecture or training parameters to achieve better performance.</p></li></ul><p><strong>Conclusion</strong></p><p>In summary, incorporating the DST into deep learning can help us better handle uncertainty and improve the interpretability of our models, leading to more robust and reliable predictions in situations with incomplete or ambiguous data..</p></div><footer></footer></article></section></div><script type=text/javascript src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></main><script src=https://AIThoughtLab.github.io/ThinkingAI/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script></body></html>