<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on AI for HUMANITY</title><link>https://AIThoughtLab.github.io/ThinkingAI/posts/</link><description>Recent content in Posts on AI for HUMANITY</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Mon, 02 Jan 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://AIThoughtLab.github.io/ThinkingAI/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Biological Image Analysis using ImageJ</title><link>https://AIThoughtLab.github.io/ThinkingAI/posts/ij/</link><pubDate>Mon, 02 Jan 2023 00:00:00 +0000</pubDate><guid>https://AIThoughtLab.github.io/ThinkingAI/posts/ij/</guid><description>How to use ImageJ for biological image analysis
Image analysis is a critical step in many research fields, including biology, medicine, and materials science. One widely-used software for image analysis is ImageJ, which is a powerful, user-friendly program developed by the National Institutes of Health (NIH).
ImageJ allows users to analyze digital images by performing a range of quantitative measurements, such as area, intensity, and particle size. It also has a wide variety of image processing and manipulation tools, including filters, segmentation, and thresholding.</description></item><item><title>Bayesian optimization of time perception</title><link>https://AIThoughtLab.github.io/ThinkingAI/posts/bayesianoptimization/</link><pubDate>Thu, 13 Oct 2022 00:00:00 +0000</pubDate><guid>https://AIThoughtLab.github.io/ThinkingAI/posts/bayesianoptimization/</guid><description>Introduction: Context and Motivation
Humans are accurate at timing sub-second to minute intervals in daily routines, but their experience of time can be biased in different contexts. Traditionally, these biases were explained by the decay of modality-specific representations, changes in the internal clock speed, and memory mixing of different temporal representations. Recently, researchers have used Bayesian inference to analyze contextual calibration and improve performance, but how this links to temporal processing is unclear.</description></item><item><title>Understanding the Dempster-Shafer Theory for Deep Learning</title><link>https://AIThoughtLab.github.io/ThinkingAI/posts/ds/</link><pubDate>Fri, 30 Sep 2022 00:00:00 +0000</pubDate><guid>https://AIThoughtLab.github.io/ThinkingAI/posts/ds/</guid><description>Introduction
The Dempster-Shafer theory (DST), named after its creators Arthur Dempster and Glenn Shafer, is a powerful mathematical framework for representing and managing uncertain information. It is particularly useful in situations where the available data is incomplete, imprecise, or contradictory. In this post, we will introduce the core concepts of the Dempster-Shafer theory, explore its practical applications in deep learning, and discuss its advantages over traditional probability theory.
Belief functions</description></item><item><title>Marching Cube Algorithm</title><link>https://AIThoughtLab.github.io/ThinkingAI/posts/mc/</link><pubDate>Wed, 18 May 2022 00:00:00 +0000</pubDate><guid>https://AIThoughtLab.github.io/ThinkingAI/posts/mc/</guid><description>Marching Cube Algorithm - an overview:
The Marching Cube Algorithm is a well known algorithm in computer graphics and scientific visualization for creating a 3D surface mesh from a 3D scalar field. The input of marching cube algorithm is a 3D voxels or 3D coordinate points and the output is a triangular mesh that represents the isosurface of the scalar field.
The basic idea of the algorithm is to divide the input volume into a regular grid of cubes, with each cube having 8 corners.</description></item><item><title>Human 3D Pose Reconstruction</title><link>https://AIThoughtLab.github.io/ThinkingAI/posts/pose/</link><pubDate>Sat, 26 Dec 2020 00:00:00 +0000</pubDate><guid>https://AIThoughtLab.github.io/ThinkingAI/posts/pose/</guid><description>Human 3D Pose Reconstruction
This blog focuses on performing 3D reconstruction of human poses using multiple views captured by a calibrated system. To achieve this, a deep neural network called OpenPose is used to estimate the location of the joints in the human body. The OpenPose model has been trained to recognize 25 different joints in the human body, such as the head, shoulders, elbows, hips, knees, and ankles. These joints are critical for determining the posture and movement of a person.</description></item><item><title>Choregraphe Software for Pepper Robot</title><link>https://AIThoughtLab.github.io/ThinkingAI/posts/choregraphe/</link><pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate><guid>https://AIThoughtLab.github.io/ThinkingAI/posts/choregraphe/</guid><description>The purpose of this post is to build up a robot speaking system with body language and speech text and speech sound in Choregraphe. See the documentation here or download the software here.
The process is very straight forward using this software.
Step-1: Firstly we opened Choregraphe App and connected to the virtual robot &amp;lsquo;NAO H21​&amp;rsquo;. After that, we selected the &amp;lsquo;Say&amp;rsquo; node, ​&amp;rsquo;Delay&amp;rsquo; node and &amp;lsquo;Play Sound&amp;rsquo; ​node on the Box library.</description></item><item><title>Gradient Decent, Stochastic Gradient Descent and Adam Optimization Algorithm</title><link>https://AIThoughtLab.github.io/ThinkingAI/posts/adam/</link><pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate><guid>https://AIThoughtLab.github.io/ThinkingAI/posts/adam/</guid><description>Optimization Algorithms
Before we start the Adaptive Moment Estimation (Adam) optimization algorithm, we first see what is Gradient Decent (GD) optimization and how it works and then discuss about Stochastic Gradient Descent (SGD) and finally Adam optimization.
Gradient Decent (GD)
GD is one of the most well known optimization algorithm available in machine learning and deep learning framework. Lets say we have a scalar cost function C which is continuous in the domain \(R_n\) (n-dimensional real vector space), takes the input vector \(x ( = x_1, x_2 &amp;hellip; x_n)\) of length \(n\) and we would like to find an optimal value of this cost function.</description></item><item><title>Keras – High Level API</title><link>https://AIThoughtLab.github.io/ThinkingAI/posts/kerasapi/</link><pubDate>Wed, 10 Apr 2019 00:00:00 +0000</pubDate><guid>https://AIThoughtLab.github.io/ThinkingAI/posts/kerasapi/</guid><description>What is Keras?
It is a high-level neural network API, written in Python and able to running on top of TensorFlow. It is a very useful API, which enables us fast experimentation. Keras acts as an interface for the TensorFlow library. The task here is to study the image classification problem using notMNIST dataset. This dataset contains images of letters from A – J inclusive (dowload here). See the figure below to get an idea;</description></item><item><title>TensorFlow and the Low Level API - Part 2</title><link>https://AIThoughtLab.github.io/ThinkingAI/posts/fashion-mnist_tf2/</link><pubDate>Wed, 03 Apr 2019 00:00:00 +0000</pubDate><guid>https://AIThoughtLab.github.io/ThinkingAI/posts/fashion-mnist_tf2/</guid><description>As a continuation from the previous part-1, in this post we will discuss a full multi-class classification problem (all 10 classes for Fashion MNIST). Using TensorFlow’s low level API (in graph mode) let us build a multi-layer neural network. We will define our architecture as follow:
Layer 1: 300 neurons (ReLu activation functions). Layer 2: 100 neurons (ReLu activation function) Layer 3: Softmax Layer Learning rate: 0.01 (with Gradient Descent). We will import the necessary libraries first;</description></item><item><title>TensorFlow and the Low Level API - Part 1</title><link>https://AIThoughtLab.github.io/ThinkingAI/posts/fashion-mnist_tf/</link><pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate><guid>https://AIThoughtLab.github.io/ThinkingAI/posts/fashion-mnist_tf/</guid><description>What is TensorFlow?
TensorFlow is an open-source software library for dataflow and differentiable programming across a range of tasks. It is primarily used for machine learning and deep learning applications. TensorFlow provides a high-level API for building and training machine learning models, as well as a low-level API for defining mathematical operations. With TensorFlow, users can easily build, train, and deploy complex models on a variety of platforms, including desktops, servers, and mobile devices.</description></item><item><title>How to create a static website using hugo?</title><link>https://AIThoughtLab.github.io/ThinkingAI/posts/websitewithhugo/</link><pubDate>Thu, 28 Feb 2019 00:00:00 +0000</pubDate><guid>https://AIThoughtLab.github.io/ThinkingAI/posts/websitewithhugo/</guid><description>Creating a website using Hugo is a straightforward process that can be broken down into a few simple steps. Why hugo?
Pros
No server side code Fast to render Often more secure Content is versioned Cons
No dynamic contents No database No real time UI etc Let us try out now;
Install Hugo: Before you can start creating your website, you&amp;rsquo;ll need to install Hugo on your computer. You can download the latest version of Hugo from the Hugo website (https://gohugo.</description></item></channel></rss>