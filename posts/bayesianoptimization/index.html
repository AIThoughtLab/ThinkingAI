<!doctype html><html lang=en><head><title>Bayesian optimization of time perception ¬∑ AI for HUMANITY</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Mohamed ABDUL GAFOOR"><meta name=description content="Introduction: Context and Motivation
Humans are accurate at timing sub-second to minute intervals in daily routines, but their experience of time can be biased in different contexts. Traditionally, these biases were explained by the decay of modality-specific representations, changes in the internal clock speed, and memory mixing of different temporal representations. Recently, researchers have used Bayesian inference to analyze contextual calibration and improve performance, but how this links to temporal processing is unclear."><meta name=keywords content="blog,developer,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="Bayesian optimization of time perception"><meta name=twitter:description content="Introduction: Context and Motivation
Humans are accurate at timing sub-second to minute intervals in daily routines, but their experience of time can be biased in different contexts. Traditionally, these biases were explained by the decay of modality-specific representations, changes in the internal clock speed, and memory mixing of different temporal representations. Recently, researchers have used Bayesian inference to analyze contextual calibration and improve performance, but how this links to temporal processing is unclear."><meta property="og:title" content="Bayesian optimization of time perception"><meta property="og:description" content="Introduction: Context and Motivation
Humans are accurate at timing sub-second to minute intervals in daily routines, but their experience of time can be biased in different contexts. Traditionally, these biases were explained by the decay of modality-specific representations, changes in the internal clock speed, and memory mixing of different temporal representations. Recently, researchers have used Bayesian inference to analyze contextual calibration and improve performance, but how this links to temporal processing is unclear."><meta property="og:type" content="article"><meta property="og:url" content="https://AIThoughtLab.github.io/ThinkingAI/posts/bayesianoptimization/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-10-13T00:00:00+00:00"><meta property="article:modified_time" content="2022-10-13T00:00:00+00:00"><link rel=canonical href=https://AIThoughtLab.github.io/ThinkingAI/posts/bayesianoptimization/><link rel=preload href="https://AIThoughtLab.github.io/ThinkingAI/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin><link rel=stylesheet href=https://AIThoughtLab.github.io/ThinkingAI/css/coder.min.36f76aaf39a14ecf5c3a3c6250dcaf06c238b3d8365d17d646f95cb1874e852b.css integrity="sha256-NvdqrzmhTs9cOjxiUNyvBsI4s9g2XRfWRvlcsYdOhSs=" crossorigin=anonymous media=screen><link rel=stylesheet href=https://AIThoughtLab.github.io/ThinkingAI/css/coder-dark.min.593028e7f7ac55c003b79c230d1cd411bb4ca53b31556c3abb7f027170e646e9.css integrity="sha256-WTAo5/esVcADt5wjDRzUEbtMpTsxVWw6u38CcXDmRuk=" crossorigin=anonymous media=screen><link rel=icon type=image/png href=https://AIThoughtLab.github.io/ThinkingAI/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=https://AIThoughtLab.github.io/ThinkingAI/images/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=https://AIThoughtLab.github.io/ThinkingAI/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=https://AIThoughtLab.github.io/ThinkingAI/images/apple-touch-icon.png><link rel=manifest href=https://AIThoughtLab.github.io/ThinkingAI/site.webmanifest><link rel=mask-icon href=https://AIThoughtLab.github.io/ThinkingAI/images/safari-pinned-tab.svg color=#5bbad5><meta name=generator content="Hugo 0.110.0"></head><body class="preload-transitions colorscheme-dark"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://AIThoughtLab.github.io/ThinkingAI/>AI for HUMANITY</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/about/>About</a></li><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/posts/>Blog</a></li><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/projects/>Projects</a></li><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/innovations/>Innovations</a></li><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/personal/>Personal</a></li><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/contact/>Contact me</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://AIThoughtLab.github.io/ThinkingAI/posts/bayesianoptimization/>Bayesian optimization of time perception</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa fa-calendar" aria-hidden=true></i>
<time datetime=2022-10-13T00:00:00Z>October 13, 2022</time></span>
<span class=reading-time><i class="fa fa-clock-o" aria-hidden=true></i>
7-minute read</span></div><div class=categories><i class="fa fa-folder" aria-hidden=true></i>
<a href=https://AIThoughtLab.github.io/ThinkingAI/categories/bayesian-optimization/>Bayesian Optimization</a></div><div class=tags><i class="fa fa-tag" aria-hidden=true></i>
<span class=tag><a href=https://AIThoughtLab.github.io/ThinkingAI/tags/bayesian/>Bayesian</a></span>
<span class=separator>‚Ä¢</span>
<span class=tag><a href=https://AIThoughtLab.github.io/ThinkingAI/tags/time-perception/>time perception</a></span>
<span class=separator>‚Ä¢</span>
<span class=tag><a href=https://AIThoughtLab.github.io/ThinkingAI/tags/psychology/>Psychology</a></span></div></div></header><div class=post-content><p><strong>Introduction: Context and Motivation</strong></p><p>Humans are accurate at timing sub-second to minute intervals in daily routines, but their experience of time can be biased in different contexts. Traditionally, these biases were explained by the decay of modality-specific representations, changes in the internal clock speed, and memory mixing of different temporal representations. Recently, researchers have used Bayesian inference to analyze contextual calibration and improve performance, but how this links to temporal processing is unclear. The article by <a href=https://www.sciencedirect.com/science/article/abs/pii/S1364661313002131>Zhuanghua Shi et al</a> reviews the influence of contextual calibration on interval timing, compares Bayesian inference with traditional timing models, and provides a roadmap for integrating the two.</p><p>Objective time: For example, adjust the running speed to catch a flying ball. We have no control over time (1 day = 24hrs).<br><figure class=center><img src=https://AIThoughtLab.github.io/ThinkingAI/images/catch.png></figure></p><p>Subjective time: During happy moment, time flies. But during sad time, time goes very slowly.</p><figure class=center><img src=https://AIThoughtLab.github.io/ThinkingAI/images/happy.png></figure><p><strong>Contextual calibration of time perception</strong></p><p>What is the paper by Zhuanghua Shi et al ll about?
Integrate a Bayesian framework with information-processing models of timing to understand the temporal calibration.</p><ul><li>Subjective durations can be easily distorted.</li></ul><p>Example 1: Vierordt‚Äôs law (Central-tendency effect):
Participants overproduce ‚Äúshort‚Äù durations and underproduce ‚Äúlong‚Äù durations. It is because the duration judgments are derived from both current and the previously experienced stimulus duration.</p><p>Observation:</p><ol><li><p>String musicians show very low biases (auditory ‚àÜt reproduction).</p></li><li><p>Expert drummers reproduce ‚àÜt at a near perfection (auditory+visual).</p></li><li><p>People with Parkinson‚Äôs disease.
They are prone to contextual manipulation based on medication. Known as temporal ‚Äúmigration‚Äù effect.</p></li></ol><p>PD with medication OFF tend to overproduce ‚Äúshort‚Äù durations and underproduce ‚Äúlong‚Äù durations - Central-tendency effect. Following is the graph;<figure class=center><img src=https://AIThoughtLab.github.io/ThinkingAI/images/pd.png></figure></p><p>Following is the figure that shows, Medication ON/OFF states. Note that the error bars are quite big for OFF medication.<figure class=center><img src=https://AIThoughtLab.github.io/ThinkingAI/images/error.png></figure>and simillary the application of Bayesian inference to medication ON/OFF for 21 sec.</p><p>In this case, the prior distribution does not change. But with medication OFF state, uncertainty in the likelihood increase. Hence the posterior is shifting to the left. Following is the figure;<figure class=center><img src=https://AIThoughtLab.github.io/ThinkingAI/images/21.png></figure></p><p>There are other examples in which subjective durations can be easily distorted;</p><p>Example 2: Time Order Error (TOE)
This says the order of the presentation matter and it can create a bias in the judgement.</p><p>Example 3: Modality Effects
Sounds are judged longer than lights. Participants simply overestimate the auditory and underestimate the visual stimuli.</p><p><strong>Traditional approaches to contextual calibration</strong></p><ol><li><p>Adaptation Level (AL) Theory:</p><ul><li><p>According to this theory, a percept of a stimulus depends on the background context. (Luminosity)</p></li><li><p>A modified version of AL theory suggest; perceived subjective duration is a linear weighted average of the sensory evidence and context.</p></li></ul><p><figure class=center><img src=https://AIThoughtLab.github.io/ThinkingAI/images/formula1.png></figure>This equation explains the Medication ON/OFF states (linear graph) that we have seen above (error bars are quite big for OFF medication).</p></li><li><p>Scalar Timing Theory:<br>This is another theory to describe cognitive process involving in time discrimination.
Following is an important formula that describe various aspects in the process;<figure class=center><img src=https://AIThoughtLab.github.io/ThinkingAI/images/formula2.png></figure></p><p>Following is a schematic for an information-processing (IP) model of scalar timing theory.<figure class=center><img src=https://AIThoughtLab.github.io/ThinkingAI/images/IPmodel.png></figure></p><p>According to this theory, standard deviation of the ‚Äútemporal estimate‚Äù increases linearly with the mean of the duration. This property knows as <strong>scalar property</strong>.
This linearity comes from the memory translation constant K. Following figure explains it;<figure class=center><img src=https://AIThoughtLab.github.io/ThinkingAI/images/subtime.png></figure></p><p>It is important to note that the <strong>Scalar property</strong> also induce memory-mixing (Modality effect). Following figure shows the modality effect;<figure class=center><img src=https://AIThoughtLab.github.io/ThinkingAI/images/modality.png></figure></p><ul><li>Duration bisection procedure using anchor duration of 2 s & 8 s.</li><li>Participants were exposed to a range of intermediate durations.</li></ul><p><strong>All participants reproduced the classic finding that ‚Äúsounds are judged longer than lights‚Äù.</strong></p></li></ol><p><strong>Bayesian inference on temporal contextual calibration</strong></p><ul><li>Linear-weighted average model + Scalar timing theory help us to understand memory-mixing phenomena etc.</li><li>However, it does not explain what factor(s) quantitatively determine the level of contextual calibration.</li></ul><p>Why Bayesian is good? Because it combines prior knowledge in the statistical distribution.
What is Bayes&rsquo; Formula? It is a mathematical formula used in Bayesian statistics that expresses the relationship between the probability of an event (A) given some prior information (B), and the probability of the prior information given the event. It is named after Thomas Bayes, an 18th-century statistician who first described the formula.</p><p>The formula is stated as:</p><pre><code>P(D|S) = (P(S|D) * P(D)) / P(S)
</code></pre><p>where:</p><ul><li>P(D|S) is the probability of event A given that event B has occurred, also known as the posterior probability.</li><li>P(S|D) is the probability of event B given that event A has occurred, also known as the likelihood.</li><li>P(D) is the prior probability of event A occurring.</li><li>P(S) is the prior probability of event B occurring.</li></ul><p>Bayes&rsquo; Formula is used in Bayesian statistics to update beliefs or probabilities based on new data. It allows for the incorporation of prior information and the computation of posterior probabilities in the light of new evidence. Computing posterior distribution is knowns as the inference problem.</p><p>Similarity between Bayesian inference and information - processing model.</p><ul><li>P(S|D) ~ N(ùûµ_s, ùûº_s), Likelihood function of D and</li><li>P(D) ~ N(ùûµ_p, ùûº_p), Prior probability of D</li></ul><p><figure class=center><img src=https://AIThoughtLab.github.io/ThinkingAI/images/ip1.png></figure>By minimizing the loss function L, we obtain posterior mean. Where w_p is the waited variance.<figure class=center><img src=https://AIThoughtLab.github.io/ThinkingAI/images/mean.png></figure></p><p><strong>Bayesian inference for predicting central-tendency</strong></p><p><em>Jazayeri et al.</em> published an interesting paper (Temporal context calibrates interval timing) on it. Where they have choosen partially overlapped intervals.<figure class=center><img src=https://AIThoughtLab.github.io/ThinkingAI/images/inference.png></figure></p><p>The paper shows how to use Bayesian formula to describe ‚ÄúCentral-tendency‚Äù effect in temporal reproduction.<figure class=center><img src=https://AIThoughtLab.github.io/ThinkingAI/images/tendency.png></figure></p><p>The figure illustrate the followings;</p><ul><li>Production times monotonically increases with sample interval.</li><li>Average production time deviated from the line y = x and towards the mean of the prior (systematic bias).</li><li>For ‚Äúlong‚Äù, deviation is high.. Strong bias.</li></ul><p>How Bayesian inference is computed using the Bayes least-square (BLS) estimator?</p><figure class=center><img src=https://AIThoughtLab.github.io/ThinkingAI/images/bls.png></figure><ul><li>The mean of the posterior determines the estimate. The resulting mapping function, f_BLS, is sigmoidal in shape.</li><li>There are other estimators; MLE, MAP.</li></ul><p><strong>Bayesian inference for predicting Modality effect</strong></p><ul><li><p>Pulses are integrated at a faster rate for auditory stimuli than for visual stimuli.</p></li><li><p>The internal reference of the mean duration between the ‚Äúshort‚Äù (S) and ‚Äúlong‚Äù (L) anchor durations is larger for auditory stimuli (M_a) than for visual stimuli (M_v).</p></li><li><p>M_a and M_v are two independent Gaussians.</p></li><li><p>When mixed within the same memory distribution, M_av is a linear-weighted average of M_a and M_v.</p></li></ul><p><figure class=center><img src=https://AIThoughtLab.github.io/ThinkingAI/images/pse.png></figure>Here, the PSE is the ‚Äúpoint of subjective equality‚Äù, when the two stimuli (auditory and visual) look subjectively the same, and thus, an observer would choose randomly between them.
But recall that pulses are integrated at different rate for auditory and visual stimuli.</p><p>Integrating Bayesian inference with scalar timing theory.</p><ul><li>Let&rsquo;s compare key components of both methods.</li></ul><table><thead><tr><th>Similarity</th><th>Difference</th></tr></thead><tbody><tr><td>Likelihood, the prior probability, and the loss function for optimization can be mapped to the clock, memory, and decision stage.</td><td>Scalar timing theory assume, scalar property comes from memory translation constant. But Bayesian framework does not provide any specific assumption.</td></tr><tr><td>Clock stage responsible for measurement of external event, while likelihood give insight into physical duration.</td><td>Bayesian framework use Baye rule to update the memory, while scalar timing theory uses dynamic memory update. eq-2</td></tr><tr><td>Scalar timing theory has 2 memories (working+reference), while Bayesian inference assumes prior and posterior probability distribution.</td><td>Preferred loss function in the scalar timing theory is relative error, where as in the Bayesian framework we use squared-error.</td></tr></tbody></table><p><strong>Concluding remarks</strong></p><ul><li><p>This studies shows that the three essential components of a Bayesian framework (i.e., likelihood, prior, and loss function) are closely linked to the clock, memory, and decision stages advocated by scalar timing theory and incorporated into other timing models.</p></li><li><p>The Bayesian framework combined with scalar timing theory not only provides a new perspective on interval timing, but also offers quantitative predictions of distortions in temporal memory for normal participants and patients.</p></li><li><p>This integrated system should be combine with the striatal beat‚Äìfrequency framework to expand our understanding in the mechanistic level.</p></li></ul><p>Visit to see the Python implimentation for central tendancy effect;
<a href=https://github.com/AIThoughtLab/Bayesian-optimization>Bayesian Optimization</a></p></div><footer></footer></article></section></div><script type=text/javascript src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></main><script src=https://AIThoughtLab.github.io/ThinkingAI/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script></body></html>