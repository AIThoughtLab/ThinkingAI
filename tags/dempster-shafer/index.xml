<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Dempster-Shafer on AI for HUMANITY</title><link>https://AIThoughtLab.github.io/ThinkingAI/tags/dempster-shafer/</link><description>Recent content in Dempster-Shafer on AI for HUMANITY</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 30 Sep 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://AIThoughtLab.github.io/ThinkingAI/tags/dempster-shafer/index.xml" rel="self" type="application/rss+xml"/><item><title>Understanding the Dempster-Shafer Theory for Deep Learning</title><link>https://AIThoughtLab.github.io/ThinkingAI/posts/ds/</link><pubDate>Fri, 30 Sep 2022 00:00:00 +0000</pubDate><guid>https://AIThoughtLab.github.io/ThinkingAI/posts/ds/</guid><description>Introduction
The Dempster-Shafer theory (DST), named after its creators Arthur Dempster and Glenn Shafer, is a powerful mathematical framework for representing and managing uncertain information. It is particularly useful in situations where the available data is incomplete, imprecise, or contradictory. In this post, we will introduce the core concepts of the Dempster-Shafer theory, explore its practical applications in deep learning, and discuss its advantages over traditional probability theory.
Belief functions</description></item></channel></rss>