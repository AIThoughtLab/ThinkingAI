<!doctype html><html lang=en><head><title>AI and the Everything in the Whole Wide World Benchmark · AI for HUMANITY</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Mohamed ABDUL GAFOOR"><meta name=description content="This is my personal point of view on the AI and the Everything in the Whole Wide World Benchmark by Inioluwa Deborah Raji et al. The article can be download at AI and the Everything in the Whole Wide World Benchmark.
I think the paper was accepted for publication at NEURIPS 2021 as it highlights the risk of over-reliance of machine learning on benchmarking. Growing enthusiasm in North Star type dataset, which positions itself (or hyped by the ML communities) as benchmarks for &ldquo;general purpose&rdquo; visual object recognition or language understanding which in many ways, authors believe, creates undesirable consequences."><meta name=keywords content="blog,developer,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="AI and the Everything in the Whole Wide World Benchmark"><meta name=twitter:description content="This is my personal point of view on the AI and the Everything in the Whole Wide World Benchmark by Inioluwa Deborah Raji et al. The article can be download at AI and the Everything in the Whole Wide World Benchmark.
I think the paper was accepted for publication at NEURIPS 2021 as it highlights the risk of over-reliance of machine learning on benchmarking. Growing enthusiasm in North Star type dataset, which positions itself (or hyped by the ML communities) as benchmarks for &ldquo;general purpose&rdquo; visual object recognition or language understanding which in many ways, authors believe, creates undesirable consequences."><meta property="og:title" content="AI and the Everything in the Whole Wide World Benchmark"><meta property="og:description" content="This is my personal point of view on the AI and the Everything in the Whole Wide World Benchmark by Inioluwa Deborah Raji et al. The article can be download at AI and the Everything in the Whole Wide World Benchmark.
I think the paper was accepted for publication at NEURIPS 2021 as it highlights the risk of over-reliance of machine learning on benchmarking. Growing enthusiasm in North Star type dataset, which positions itself (or hyped by the ML communities) as benchmarks for &ldquo;general purpose&rdquo; visual object recognition or language understanding which in many ways, authors believe, creates undesirable consequences."><meta property="og:type" content="article"><meta property="og:url" content="https://AIThoughtLab.github.io/ThinkingAI/personal/benchmark/"><meta property="article:section" content="personal"><meta property="article:published_time" content="2022-02-14T00:00:00+00:00"><meta property="article:modified_time" content="2022-02-14T00:00:00+00:00"><link rel=canonical href=https://AIThoughtLab.github.io/ThinkingAI/personal/benchmark/><link rel=preload href="https://AIThoughtLab.github.io/ThinkingAI/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin><link rel=stylesheet href=https://AIThoughtLab.github.io/ThinkingAI/css/coder.min.36f76aaf39a14ecf5c3a3c6250dcaf06c238b3d8365d17d646f95cb1874e852b.css integrity="sha256-NvdqrzmhTs9cOjxiUNyvBsI4s9g2XRfWRvlcsYdOhSs=" crossorigin=anonymous media=screen><link rel=stylesheet href=https://AIThoughtLab.github.io/ThinkingAI/css/coder-dark.min.593028e7f7ac55c003b79c230d1cd411bb4ca53b31556c3abb7f027170e646e9.css integrity="sha256-WTAo5/esVcADt5wjDRzUEbtMpTsxVWw6u38CcXDmRuk=" crossorigin=anonymous media=screen><link rel=icon type=image/png href=https://AIThoughtLab.github.io/ThinkingAI/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=https://AIThoughtLab.github.io/ThinkingAI/images/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=https://AIThoughtLab.github.io/ThinkingAI/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=https://AIThoughtLab.github.io/ThinkingAI/images/apple-touch-icon.png><link rel=manifest href=https://AIThoughtLab.github.io/ThinkingAI/site.webmanifest><link rel=mask-icon href=https://AIThoughtLab.github.io/ThinkingAI/images/safari-pinned-tab.svg color=#5bbad5><meta name=generator content="Hugo 0.111.2"></head><body class="preload-transitions colorscheme-dark"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://AIThoughtLab.github.io/ThinkingAI/>AI for HUMANITY</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/about/>About</a></li><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/posts/>Blog</a></li><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/projects/>Projects</a></li><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/innovations/>Innovations</a></li><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/personal/>Personal</a></li><li class=navigation-item><a class=navigation-link href=https://AIThoughtLab.github.io/ThinkingAI/contact/>Contact me</a></li></ul></section></nav><div class=content><section class="container page"><article><header><h1 class=title><a class=title-link href=https://AIThoughtLab.github.io/ThinkingAI/personal/benchmark/>AI and the Everything in the Whole Wide World Benchmark</a></h1></header><p>This is my personal point of view on the <strong>AI and the Everything in the Whole Wide World Benchmark</strong> by <em>Inioluwa Deborah Raji et al.</em>
The article can be download at <a href=https://arxiv.org/pdf/2111.15366.pdf>AI and the Everything in the Whole Wide World Benchmark</a>.</p><p>I think the paper was accepted for publication at NEURIPS 2021 as it highlights the risk of over-reliance of machine learning on benchmarking. Growing enthusiasm in North Star type dataset, which positions itself (or hyped by the ML communities) as benchmarks for &ldquo;general purpose&rdquo; visual object recognition or language understanding which in many ways, authors believe, creates undesirable consequences. Moreover, the paper critically supports its arguments with historical background and tries to convey a message that the machine learning communities should not confuse &ldquo;models of reality&rdquo; with &ldquo;reality&rdquo; itself.</p><p>The paper mainly focuses on two &ldquo;general&rdquo; dataset-based benchmarks, namely ImageNet and GLUE. For example in the case of ImageNet, the project said to be an &ldquo;attempt to map the entire world of objects&rdquo; is similar to the claim in the Grover&rsquo;s museum story to showcase &ldquo;everything in the whole wide world&rdquo;. Moreover, the paper discusses the validity and the limitation of a &ldquo;general&rdquo; benchmark, such as limited task design, de-contextualized data & performance reporting; in which the authors emphasize the fact that no dataset is neural and there are inherent subjective biases. For example, specific to certain cultural views or how the photos were taken during the creation of the dataset etc. According to the authors, all these leads to inappropriate community use.</p><p>Strengths and Weaknesses: The paper brings an important philosophical view of &ldquo;designed benchmarks&rdquo;, either intentionally or unintentionally created biases could directly threaten the construct validity. The authors rigorously develop the arguments and question about the validity and imperfect nature of &ldquo;general&rdquo; dataset-based benchmarks. By incorporating historical arguments, the authors highlight from previous works that the state of the art chasing or metric chasing as an ethical issue leads to manipulation and can create long term damages to the field of General Artificial Intelligence.</p><p>The paper elucidates the over-reliance of machine learning on benchmarking very well, nevertheless, proposed solutions could have been in the main part of the paper itself instead of in the appendix. Moreover, for the question of attaining neutrality in the benchmark and capturing &ldquo;general capabilities&rdquo; is far more difficult or even impossible in the current context, but is that feasible in the future? Is that all about how large & diverse the Grover&rsquo;s museum space is?. Furthermore, in epistemology, it is always hard and an open-ended problem to define what General Intelligence is. In that sense, saying the tasks/subtasks that we develop in machine learning “general” benchmarks are not good abstractions is also questionable.</p></article></section></div><script type=text/javascript src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></main><script src=https://AIThoughtLab.github.io/ThinkingAI/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script></body></html>